{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def find_botvinnik_names(df):\n",
    "    # Concatenate white and black columns into a single series\n",
    "    all_players = pd.concat([df['white'], df['black']])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Get unique player names\n",
    "    unique_players = all_players.unique()\n",
    "    \n",
    "    # Filter for names containing \"Botvinnik\" (case-insensitive)\n",
    "    botvinnik_names = [name for name in unique_players \n",
    "                       if \"fischer\" in name.lower()]\n",
    "    \n",
    "    return botvinnik_names\n",
    "\n",
    "# Example usage:\n",
    "botvinnik_names = find_botvinnik_names(df)\n",
    "print(botvinnik_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_botvinnik_efficient(df):\n",
    "    # List of variations that represent Mikhail Botvinnik\n",
    "    mikhail_variations = [\n",
    "        'Botvinnik, M.', \n",
    "        'Botvinnik, Mikhail URS', \n",
    "        'Botvinnik, Mikhail',\n",
    "        'Botvinnik, M2.',\n",
    "        'Botvinnik, Mikhail2',\n",
    "        'Botvinnik,M2'\n",
    "    ]\n",
    "    \n",
    "    # Create a copy of the dataframe\n",
    "    standardized_df = df.copy()\n",
    "    \n",
    "    # Create a mapping dictionary for replacement\n",
    "    name_mapping = {variation: 'Botvinnik, Mikhail' for variation in mikhail_variations}\n",
    "    \n",
    "    # Replace in both columns at once\n",
    "    standardized_df['white'] = standardized_df['white'].replace(name_mapping)\n",
    "    standardized_df['black'] = standardized_df['black'].replace(name_mapping)\n",
    "    \n",
    "    return standardized_df\n",
    "\n",
    "standardized_df = standardize_botvinnik_efficient(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Tal, Mikhail number of games for white and black\n",
    "# print(df[df['white'] == 'Tal, Mikhail']['white'].count())\n",
    "# print(df[df['black'] == 'Tal, Mikhail']['black'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1r/jcq7c7353hsb6scsnq4g2pp00000gn/T/ipykernel_60042/2361612335.py:5: DtypeWarning: Columns (3,9,10,12,13,14,17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of df: 7244333\n",
      "len of df: 6489794\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define path to your file\n",
    "file_path = '/Users/samir/Desktop/Uppsala/Thesis/thesis_chess_code/data/processed/lumbrasgigabase/chess_games_clean.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# len of df\n",
    "print(f'len of df: {len(df)}')\n",
    "\n",
    "# remove where event starts with Titled Tue, first change dtype to string\n",
    "df['event'] = df['event'].astype(str)\n",
    "df = df[~df['event'].str.startswith('Titled Tue')]\n",
    "\n",
    "# save df\n",
    "df.to_csv('/Users/samir/Desktop/Uppsala/Thesis/thesis_chess_code/data/processed/lumbrasgigabase/chess_games_clean_no_titled_tue.csv', index=False)\n",
    "\n",
    "# len of df\n",
    "print(f'len of df: {len(df)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1r/jcq7c7353hsb6scsnq4g2pp00000gn/T/ipykernel_74285/3777764921.py:5: DtypeWarning: Columns (3,9,10,12,13,14,17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of df: 6489794\n",
      "len of df: 6480244\n",
      "len of df: 6202573\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define path to your file\n",
    "file_path = '/Users/samir/Desktop/Uppsala/Thesis/thesis_chess_code/data/processed/lumbrasgigabase/chess_games_clean_no_titled_tue.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# len of df\n",
    "print(f'len of df: {len(df)}')\n",
    "\n",
    "# remove where white_title or black_title is BOT\n",
    "df = df[df['white_title'] != 'BOT']\n",
    "df = df[df['black_title'] != 'BOT']\n",
    "\n",
    "# len of df\n",
    "print(f'len of df: {len(df)}')\n",
    "\n",
    "\n",
    "# remove events that contains rapid or blitz or bullet lower case\n",
    "# First ensure event column is string type to avoid float error\n",
    "df['event'] = df['event'].astype(str)\n",
    "# Then filter out rows containing rapid, blitz, or bullet\n",
    "df = df[~df['event'].str.contains('rapid|blitz|bullet', case=False)]\n",
    "\n",
    "# len of df\n",
    "print(f'len of df: {len(df)}')\n",
    "\n",
    "# save df\n",
    "df.to_csv('/Users/samir/Desktop/Uppsala/Thesis/thesis_chess_code/data/processed/lumbrasgigabase/chess_games_clean_no_titled_tue_no_bot_no_rapid_blitz_bullet.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event                    0\n",
      "site                152214\n",
      "date                     0\n",
      "round                73506\n",
      "white                    0\n",
      "black                    0\n",
      "result                   0\n",
      "white_elo           841848\n",
      "black_elo           851828\n",
      "white_title        5820036\n",
      "black_title        5823422\n",
      "eco                      0\n",
      "opening            6153069\n",
      "time_control       6143867\n",
      "import_date        5980753\n",
      "source                   0\n",
      "moves                    0\n",
      "eval_info          6163440\n",
      "clock_info         6074706\n",
      "avg_elo            1150067\n",
      "elo_difference     1150067\n",
      "move_count               0\n",
      "result_category          0\n",
      "has_eval_info            0\n",
      "has_clock_info           0\n",
      "eco_family               0\n",
      "year                     0\n",
      "dtype: int64\n",
      "source\n",
      "LumbrasGigaBase    6202573\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# null count\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# value counts of source\n",
    "print(df['source'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of df: 6202573\n",
      "len of df3: 3790224\n"
     ]
    }
   ],
   "source": [
    "# in df remove where unique player has less than 100 games\n",
    "# Get players with at least 100 games\n",
    "frequent_white_players = df['white'].value_counts()[df['white'].value_counts() >= 100].index\n",
    "frequent_black_players = df['black'].value_counts()[df['black'].value_counts() >= 100].index\n",
    "\n",
    "# Filter the dataframe to only include games where both players have at least 100 games\n",
    "df3 = df[df['white'].isin(frequent_white_players) | df['black'].isin(frequent_black_players)]\n",
    "\n",
    "# len of df\n",
    "print(f'len of df: {len(df)}')\n",
    "\n",
    "# len of df3\n",
    "print(f'len of df3: {len(df3)}')\n",
    "\n",
    "# save df3\n",
    "df3.to_csv('/Users/samir/Desktop/Uppsala/Thesis/thesis_chess_code/data/processed/lumbrasgigabase/chess_games_clean_no_titled_tue_no_bot_no_rapid_blitz_bullet_min_100_games.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of df4: 3759666\n"
     ]
    }
   ],
   "source": [
    "# remove where event contains speed\n",
    "df4 = df3[~df3['event'].fillna('').str.contains('speed', case=False)]\n",
    "\n",
    "# len of df4\n",
    "print(f'len of df4: {len(df4)}')\n",
    "\n",
    "# save df4\n",
    "df4.to_csv('/Users/samir/Desktop/Uppsala/Thesis/thesis_chess_code/data/processed/lumbrasgigabase/chess_games_clean_no_titled_tue_no_bot_no_rapid_blitz_bullet_min_100_games_no_speed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1r/jcq7c7353hsb6scsnq4g2pp00000gn/T/ipykernel_86113/1453465367.py:6: DtypeWarning: Columns (3,9,10,12,13,14,17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df4 = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of df5: 3661688\n",
      "len of df5: 3661688\n"
     ]
    }
   ],
   "source": [
    "# remove where site contains chess.com\n",
    "import pandas as pd\n",
    "\n",
    "# Define path to your file\n",
    "file_path = '/Users/samir/Desktop/Uppsala/Thesis/thesis_chess_code/data/processed/lumbrasgigabase/chess_games_clean_no_titled_tue_no_bot_no_rapid_blitz_bullet_min_100_games_no_speed.csv'\n",
    "df4 = pd.read_csv(file_path)\n",
    "\n",
    "df5 = df4[~df4['site'].fillna('').str.contains('chess.com', case=False)]\n",
    "\n",
    "# len of df5\n",
    "print(f'len of df5: {len(df5)}')\n",
    "\n",
    "\n",
    "# save df5\n",
    "df5.to_csv('/Users/samir/Desktop/Uppsala/Thesis/thesis_chess_code/data/processed/lumbrasgigabase/chess_games_clean_no_titled_tue_no_bot_no_rapid_blitz_bullet_min_100_games_no_speed_no_chess_com.csv', index=False)\n",
    "\n",
    "# len of df5\n",
    "print(f'len of df5: {len(df5)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of df6: 3660298\n"
     ]
    }
   ],
   "source": [
    "# remove where white or black contains stockfish, alphazero, leela, komodo, houdini\n",
    "df6 = df5[~df5['white'].str.contains('stockfish|alphazero|leela|komodo|houdini', case=False) & ~df5['black'].str.contains('stockfish|alphazero|leela|komodo|houdini', case=False)]\n",
    "\n",
    "\n",
    "# len of df6\n",
    "print(f'len of df6: {len(df6)}')\n",
    "\n",
    "# save df6\n",
    "df6.to_csv('/Users/samir/Desktop/Uppsala/Thesis/thesis_chess_code/data/processed/lumbrasgigabase/chess_games_clean_no_titled_tue_no_bot_no_rapid_blitz_bullet_min_100_games_no_speed_no_chess_com_elo_2400_no_stockfish_alphazero_leela_komodo_houdini.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of stockfish_names: 9840\n"
     ]
    }
   ],
   "source": [
    "# unique names that contain stockfish, alphazero, leela, komodo, houdini, bot, fish, zero\n",
    "stockfish_names = df6[df6['white'].str.contains('stockfish|alphazero|leela|komodo|houdini|bot|fish|zero', case=False)]\n",
    "\n",
    "# len of stockfish_names\n",
    "print(f'len of stockfish_names: {len(stockfish_names)}')\n",
    "\n",
    "# save unique names as txt\n",
    "with open('/Users/samir/Desktop/Uppsala/Thesis/thesis_chess_code/data/processed/lumbrasgigabase/bot_names.txt', 'w') as f:\n",
    "    for name in stockfish_names['white'].unique():\n",
    "        f.write(name + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of df7: 3652312\n"
     ]
    }
   ],
   "source": [
    "# remove where white or black is in the list of bot names\n",
    "bot_names = [\n",
    "    'FireFishBOT_v2',\n",
    "    'LBOT007',\n",
    "    'Nikitosikbot_v2',\n",
    "    'RaspFish',\n",
    "    'ResoluteBot',\n",
    "    'yobot_v2',\n",
    "    'YoBot_v2',\n",
    "    'Fishbein,A',\n",
    "    'M-Z_Bot',\n",
    "    'MrChessTheBot',\n",
    "    'Nikitosikbot',\n",
    "    'NikitosikVariantsbot',\n",
    "    'sf_bot',\n",
    "    'Shineshou90_BOT'\n",
    "]\n",
    "\n",
    "df7 = df6.copy()\n",
    "for bot_name in bot_names:\n",
    "    df7 = df7[~df7['white'].str.contains(bot_name, case=True, regex=False)]\n",
    "    df7 = df7[~df7['black'].str.contains(bot_name, case=True, regex=False)]\n",
    "\n",
    "# len of df7\n",
    "print(f'len of df7: {len(df7)}')\n",
    "\n",
    "# save df7\n",
    "df7.to_csv('/Users/samir/Desktop/Uppsala/Thesis/thesis_chess_code/data/processed/lumbrasgigabase/chess_games_clean_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "white\n",
      "Korneev, Oleg                  1691\n",
      "Wall                           1655\n",
      "Carlsen, Magnus                1571\n",
      "Drazic, Sinisa                 1540\n",
      "Lalic, Bogdan                  1494\n",
      "                               ... \n",
      "Amori, Michael                    1\n",
      "Fritsch, Rudolf                   1\n",
      "Fritsch, A.                       1\n",
      "Amorim, Genaro Jose Melo De       1\n",
      "Von Schuetz, H                    1\n",
      "Name: count, Length: 187455, dtype: int64\n",
      "black\n",
      "Korneev, Oleg         1670\n",
      "Drazic, Sinisa        1534\n",
      "Carlsen, Magnus       1477\n",
      "Lalic, Bogdan         1476\n",
      "Ivanchuk, Vasyl       1450\n",
      "                      ... \n",
      "Alhamdan, Ahmed          1\n",
      "Alhasan, Hasan           1\n",
      "Saad, Amer Mohamed       1\n",
      "Khalifa, Ramy            1\n",
      "Irion                    1\n",
      "Name: count, Length: 194221, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# games of each player\n",
    "print(df7['white'].value_counts())\n",
    "print(df7['black'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save only unique players names to txt\n",
    "with open('/Users/samir/Desktop/Uppsala/Thesis/thesis_chess_code/data/processed/lumbrasgigabase/player_names.txt', 'w') as f:\n",
    "    # Combine white and black players, get unique names, and ensure each player is only listed once\n",
    "    white_players = df7['white'].unique()\n",
    "    black_players = df7['black'].unique()\n",
    "    all_players = set(white_players) | set(black_players)  # Use set union to ensure uniqueness\n",
    "    for name in all_players:\n",
    "        f.write(name + '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of df8: 50448\n"
     ]
    }
   ],
   "source": [
    "# only players from book \n",
    "\n",
    "player_names = [\n",
    "    # Activists\n",
    "    \"Alekhine, Alexander\",\n",
    "    \"Tal, Mikhail\",\n",
    "    \"Spassky, Boris V.\",\n",
    "    \"Spassky, Boris Vasilievich\",\n",
    "    \"Kasparov, Garry\",\n",
    "    \"Kasparov, G.\",\n",
    "    \"Anand, Viswanathan\",\n",
    "    \"Anand,V\",\n",
    "    \"Shirov, Alexei\",\n",
    "    \"Morozevich, Alexander\",\n",
    "    \"Topalov, Veselin\",\n",
    "    \"Pillsbury, Harry\",\n",
    "    \"Anderssen, Adolf\",\n",
    "    \"Bronstein, David I\",\n",
    "    \"Bronstein, Luis Marcos\",\n",
    "    \"Larsen, B.\",\n",
    "    \"Larsen, Bent\",\n",
    "    \"Taimanov, Mark E\",\n",
    "    \"Aronian, Levon\",\n",
    "    \"Polgar, Judit\",\n",
    "    \"Muller, K.\",\n",
    "    \n",
    "    # Theorists\n",
    "    \"Steinitz, Wilhelm\",\n",
    "    \"Botvinnik, M.\",\n",
    "    \"Botvinnik, Mikhail URS\",\n",
    "    \"Kramnik, Vladimir\",\n",
    "    \"Tarrasch, Siegbert\",\n",
    "    \"Nimzowitsch, Aron\",\n",
    "    \"Leko, Peter\",\n",
    "    \"Giri, Anish\",\n",
    "    \"Meier, Georg\",\n",
    "    \"Andersson, Ulf\",\n",
    "    \"Sedlak, Nikola\",\n",
    "    \"Tiviakov, Sergei\",\n",
    "    \"Ponomariov, Ruslan\",\n",
    "    \"Wahls, Matthias\",\n",
    "    \"Moskalenko, Viktor1\",\n",
    "    \"Moskalenko, Viktor\",\n",
    "    \"Moskalenko, V.\",\n",
    "    \"Dorfman, Iossif\",\n",
    "    \"Bangiev, Alexander\",\n",
    "    \"Hansen, Lars Bo\",\n",
    "    \n",
    "    # Reflectors\n",
    "    \"Capablanca, Jose\",\n",
    "    \"Smyslov, V.\",\n",
    "    \"Petrosian, T.\",\n",
    "    \"Karpov, A.\",\n",
    "    \"Karpov, Anatoly\",\n",
    "    \"Carlsen, Magnus\",\n",
    "    \"Adams, Michael\",\n",
    "    \"Keymer, Vincent\",\n",
    "    \"Bischoff, K.\",\n",
    "    \"Bischoff,K\",\n",
    "    \n",
    "    # Pragmatists\n",
    "    \"Fischer, R.\",\n",
    "    \"Euwe, Max\",\n",
    "    \"Korchnoi, Viktor\",\n",
    "    \"Caruana, Fabiano\",\n",
    "    \"Ding, Liren\",\n",
    "    \"Karjakin, Sergey\",\n",
    "    \"Vachier-Lagrave, Maxime\"\n",
    "]\n",
    "\n",
    "df8 = df7.copy()\n",
    "\n",
    "# remove where white or black is not in the list of player names\n",
    "df8 = df8[df8['white'].isin(player_names) | df8['black'].isin(player_names)]\n",
    "\n",
    "# len of df8\n",
    "print(f'len of df8: {len(df8)}')\n",
    "\n",
    "# save df8\n",
    "df8.to_csv('/Users/samir/Desktop/Uppsala/Thesis/thesis_chess_code/data/processed/lumbrasgigabase/chess_games_clean_final_players_from_book.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of df8 after name changes: 50448\n",
      "Taimanov, Mark E: 803\n",
      "Botvinnik, Mikhail URS: 271\n",
      "Petrosian: 312\n",
      "Larsen, Bent: 459\n",
      "Anderssen, Adolf: 305\n",
      "Capablanca, Jose: 725\n",
      "Bischoff, K.: 1165\n",
      "Polgar, Judit: 815\n",
      "Aronian, Levon: 2561\n",
      "Spassky, Boris V.: 531\n",
      "Vachier-Lagrave, Maxime: 2511\n",
      "Pillsbury, Harry: 197\n",
      "Bangiev, Alexander: 341\n",
      "Muller, K.: 213\n",
      "Kasparov, Garry: 823\n",
      "Sedlak, Nikola: 2352\n",
      "Tal, Mikhail: 566\n",
      "Karjakin, Sergey: 1951\n",
      "Carlsen, Magnus: 3048\n",
      "Korchnoi, Viktor: 1707\n",
      "Andersson, Ulf: 347\n",
      "Dorfman, Iossif: 733\n",
      "Leko, Peter: 1426\n",
      "Shirov, Alexei: 2833\n",
      "Kramnik, Vladimir: 1912\n",
      "Tarrasch, Siegbert: 235\n",
      "Ponomariov, Ruslan: 1707\n",
      "Adams, Michael: 2212\n",
      "Euwe, Max: 610\n",
      "Nimzowitsch, Aron: 228\n",
      "Morozevich, Alexander: 1394\n",
      "Tiviakov, Sergei: 2555\n",
      "Moskalenko, Viktor: 994\n",
      "Fischer: 133\n",
      "Giri, Anish: 2278\n",
      "Anand, Viswanathan: 1923\n",
      "Hansen, Lars Bo: 270\n",
      "Karpov, Anatoly: 1399\n",
      "Steinitz, Wilhelm: 308\n",
      "Bronstein, Luis Marcos: 445\n",
      "Smyslov: 217\n",
      "Alekhine, Alexander: 669\n",
      "Bronstein, David I: 412\n",
      "Meier, Georg: 1436\n",
      "Keymer, Vincent: 1074\n",
      "Caruana, Fabiano: 2356\n",
      "Ding, Liren: 1524\n",
      "Topalov, Veselin: 1486\n",
      "Wahls, Matthias: 287\n"
     ]
    }
   ],
   "source": [
    "# # count number of games for each player from book player_names list\n",
    "# for name in player_names:\n",
    "#     print(f'{name}: {df8[df8[\"white\"] == name].shape[0] + df8[df8[\"black\"] == name].shape[0]}')\n",
    "\n",
    "# change names of same players to the same name\n",
    "name_changes = {\n",
    "    \"Kasparov, G.\": \"Kasparov, Garry\",\n",
    "    \"Spassky, Boris Vasilievich\": \"Spassky, Boris V.\",\n",
    "    \"Anand,V\": \"Anand, Viswanathan\",\n",
    "    \"Larsen, B.\": \"Larsen, Bent\",\n",
    "    \"Botvinnik, M.\": \"Botvinnik, Mikhail URS\",\n",
    "    \"Moskalenko, Viktor1\": \"Moskalenko, Viktor\",\n",
    "    \"Moskalenko, V.\": \"Moskalenko, Viktor\",\n",
    "    \"Smyslov, V.\": \"Smyslov\",\n",
    "    \"Petrosian, T.\": \"Petrosian\",\n",
    "    \"Karpov, A.\": \"Karpov, Anatoly\",\n",
    "    \"Bischoff,K\": \"Bischoff, K.\",\n",
    "    \"Fischer, R.\": \"Fischer\",\n",
    "}\n",
    "\n",
    "def replace_name(name):\n",
    "    return name_changes.get(name, name)\n",
    "\n",
    "df8['white'] = df8['white'].apply(replace_name)\n",
    "df8['black'] = df8['black'].apply(replace_name)\n",
    "\n",
    "player_names = [replace_name(name) for name in player_names]\n",
    "player_names = list(set(player_names))\n",
    "\n",
    "# remove where white or black is not in the list of player names\n",
    "df8 = df8[df8['white'].isin(player_names) | df8['black'].isin(player_names)]\n",
    "\n",
    "# len of df8\n",
    "print(f'len of df8 after name changes: {len(df8)}')\n",
    "\n",
    "# save df8\n",
    "df8.to_csv('/Users/samir/Desktop/Uppsala/Thesis/thesis_chess_code/data/processed/lumbrasgigabase/chess_games_clean_final_players_from_book.csv', index=False)\n",
    "\n",
    "# count number of games for each player from book player_names list\n",
    "for name in player_names:\n",
    "    print(f'{name}: {df8[df8[\"white\"] == name].shape[0] + df8[df8[\"black\"] == name].shape[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting chess dataset cleaning process...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting chess dataset cleaning process...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Load the initial dataset\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitial dataset size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m games\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Step 1: Remove games where event starts with Titled Tue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/chess/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/chess/lib/python3.12/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/chess/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniforge3/envs/chess/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:905\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<frozen codecs>:331\u001b[0m, in \u001b[0;36mgetstate\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Base path for all files\n",
    "base_path = '/Users/samir/Desktop/Uppsala/Thesis/thesis_chess_code/data/processed/lumbrasgigabase/'\n",
    "\n",
    "# Define starting file path\n",
    "input_file = f'{base_path}chess_games_clean.csv'\n",
    "output_file = f'{base_path}chess_games_cleaned_final.csv'\n",
    "\n",
    "print(\"Starting chess dataset cleaning process...\")\n",
    "\n",
    "# Load the initial dataset\n",
    "df = pd.read_csv(input_file)\n",
    "print(f'Initial dataset size: {len(df)} games')\n",
    "\n",
    "# Step 1: Remove games where event starts with Titled Tue\n",
    "df['event'] = df['event'].astype(str)\n",
    "df = df[~df['event'].str.startswith('Titled Tue')]\n",
    "print(f'After removing Titled Tuesday events: {len(df)} games')\n",
    "\n",
    "# Step 2: Remove games with BOT players\n",
    "df = df[df['white_title'] != 'BOT']\n",
    "df = df[df['black_title'] != 'BOT']\n",
    "print(f'After removing BOT players: {len(df)} games')\n",
    "\n",
    "# Step 3: Remove rapid, blitz, and bullet games\n",
    "df = df[~df['event'].str.contains('rapid|blitz|bullet', case=False)]\n",
    "print(f'After removing rapid/blitz/bullet games: {len(df)} games')\n",
    "\n",
    "\n",
    "# Step 5: Remove games containing \"speed\" in the event name\n",
    "df = df[~df['event'].fillna('').str.contains('speed', case=False)]\n",
    "print(f'After removing speed chess events: {len(df)} games')\n",
    "\n",
    "# Step 6: Remove chess.com games\n",
    "df = df[~df['site'].fillna('').str.contains('chess.com', case=False)]\n",
    "print(f'After removing chess.com games: {len(df)} games')\n",
    "\n",
    "\n",
    "# Step 8: Remove engine players (standard engine names)\n",
    "engine_names = ['stockfish', 'alphazero', 'leela', 'komodo', 'houdini']\n",
    "df = df[~df['white'].str.contains('|'.join(engine_names), case=False)]\n",
    "df = df[~df['black'].str.contains('|'.join(engine_names), case=False)]\n",
    "print(f'After removing standard engine names: {len(df)} games')\n",
    "\n",
    "# Step 9: Remove specific bot players from the provided list\n",
    "bot_names = [\n",
    "    'FireFishBOT_v2', 'LBOT007', 'Nikitosikbot_v2', 'RaspFish', 'ResoluteBot',\n",
    "    'yobot_v2', 'YoBot_v2', 'Fishbein,A', 'M-Z_Bot', 'MrChessTheBot',\n",
    "    'Nikitosikbot', 'NikitosikVariantsbot', 'sf_bot', 'Shineshou90_BOT'\n",
    "]\n",
    "\n",
    "for bot_name in bot_names:\n",
    "    df = df[~df['white'].str.contains(bot_name, case=True, regex=False)]\n",
    "    df = df[~df['black'].str.contains(bot_name, case=True, regex=False)]\n",
    "\n",
    "print(f'Final dataset size: {len(df)} games')\n",
    "\n",
    "# Save the final clean dataset\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f'Final cleaned dataset saved to {output_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.path import Path\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Set up the figure with a specific size - increasing size for better visibility\n",
    "fig, ax = plt.subplots(figsize=(16, 10))\n",
    "fig.patch.set_facecolor('#f8f9fa')\n",
    "ax.set_facecolor('#f8f9fa')\n",
    "\n",
    "# Remove axis ticks and labels\n",
    "ax.set_xlim(0, 13)  # Increased x-range for more space\n",
    "ax.set_ylim(0, 8)   # Increased y-range for more space\n",
    "ax.axis('off')\n",
    "\n",
    "# Title - adjusted position\n",
    "ax.text(7, 7.5, 'Chess Data Preprocessing Pipeline', \n",
    "        fontsize=27, fontweight='bold', ha='center')  # Increased font size\n",
    "\n",
    "# Create boxes with rounded corners using patches\n",
    "def create_box(x, y, width, height, title, content, color, edge_color):\n",
    "    # Main box\n",
    "    box = patches.FancyBboxPatch(\n",
    "        (x, y), width, height, boxstyle=patches.BoxStyle(\"Round\", pad=0.02, rounding_size=0.1),\n",
    "        facecolor=color, edgecolor=edge_color, linewidth=2\n",
    "    )\n",
    "    ax.add_patch(box)\n",
    "    \n",
    "    # Title\n",
    "    ax.text(x + width/2, y + height - 0.3, title, \n",
    "            fontsize=16, fontweight='bold', ha='center')  # Increased font size\n",
    "    \n",
    "    # Content\n",
    "    if isinstance(content, list):\n",
    "        for i, line in enumerate(content):\n",
    "            ax.text(x + 0.3, y + height - 0.6 - i * 0.35, line, fontsize=13)  # Increased spacing and font size\n",
    "    else:\n",
    "        ax.text(x + width/2, y + height/2, content, fontsize=13, ha='center')  # Increased font size\n",
    "\n",
    "# Draw arrows\n",
    "def draw_arrow(start_x, start_y, end_x, end_y):\n",
    "    ax.annotate('', xy=(end_x, end_y), xytext=(start_x, start_y),\n",
    "                arrowprops=dict(arrowstyle='->', color='#666666', lw=2))  # Increased line width\n",
    "\n",
    "# Data Source box - adjusted positions\n",
    "create_box(1, 5, 3, 1.5, 'Data Source', \n",
    "           ['LumbrasGigaBase', '(15M games, 700K+ players)'], \n",
    "           '#e6f2ff', '#3385ff')\n",
    "\n",
    "# PGN Processing box - adjusted positions and increased size\n",
    "create_box(6, 5, 3, 1.5, 'PGN Processing', \n",
    "           ['• Memory-mapped I/O (mmap)', \n",
    "            '• Multi-core parallel processing', \n",
    "            '• Regex optimization'], \n",
    "           '#e6ffe6', '#33cc33')\n",
    "\n",
    "# Data Cleaning box - adjusted positions and increased size\n",
    "create_box(6, 3, 3, 1.5, 'Data Cleaning & Filtering', \n",
    "           ['• BOT player removal', \n",
    "            '• Time control filtering', \n",
    "            '• Invalid game removal'], \n",
    "           '#fff2e6', '#ff9933')\n",
    "\n",
    "# Game Selection box - adjusted positions and increased size\n",
    "create_box(6, 1, 3, 1.5, 'Game Selection', \n",
    "           ['• Prioritize classified players', \n",
    "            '• Balanced sampling', \n",
    "            '• Quality control checks'], \n",
    "           '#ffe6f2', '#ff3385')\n",
    "\n",
    "# Final Dataset box - adjusted positions and increased size\n",
    "create_box(9.5, 1, 3, 1.5, 'Final Dataset', \n",
    "           ['~5,000 selected games', \n",
    "            'Ready for feature extraction'], \n",
    "           '#e6e6ff', '#3333cc')\n",
    "\n",
    "# Process Overview box - adjusted positions and increased size\n",
    "create_box(1, 1, 3, 3.5, 'Process Overview', '', '#f0f0f0', '#999999')\n",
    "ax.text(1.3, 3.9, 'Input Format:', fontsize=14, fontweight='bold')\n",
    "ax.text(1.5, 3.6, '• PGN files', fontsize=13)\n",
    "ax.text(1.3, 3.2, 'Transformations:', fontsize=14, fontweight='bold')\n",
    "ax.text(1.5, 2.8, '• Extract metadata', fontsize=13)\n",
    "ax.text(1.5, 2.4, '• Clean move sequences', fontsize=13)\n",
    "ax.text(1.5, 2.0, '• Extract evaluations', fontsize=13)\n",
    "ax.text(1.3, 1.6, 'Output Format:', fontsize=14, fontweight='bold')\n",
    "ax.text(1.5, 1.2, '• Structured CSV', fontsize=13)\n",
    "\n",
    "# Key Metrics box - adjusted positions and increased size\n",
    "create_box(9.5, 3, 3, 1.5, 'Key Metrics', '', '#f0f0f0', '#999999')\n",
    "# Add color rectangles as legend\n",
    "ax.add_patch(patches.Rectangle((9.7, 3.9), 0.25, 0.25, facecolor='#e6f2ff', edgecolor='#3385ff'))\n",
    "ax.text(10, 4.0, 'Initial: 15M games', fontsize=13)\n",
    "ax.add_patch(patches.Rectangle((9.7, 3.5), 0.25, 0.25, facecolor='#fff2e6', edgecolor='#ff9933'))\n",
    "ax.text(10, 3.6, 'After cleaning: ~10M', fontsize=13)\n",
    "ax.add_patch(patches.Rectangle((9.7, 3.1), 0.25, 0.25, facecolor='#e6e6ff', edgecolor='#3333cc'))\n",
    "ax.text(10, 3.2, 'Final: ~5K games', fontsize=13)\n",
    "\n",
    "# Draw arrows connecting the boxes - adjusted positions\n",
    "# Horizontal arrows\n",
    "draw_arrow(4, 5.75, 6, 5.75)  # Data Source to PGN Processing\n",
    "draw_arrow(9, 1.75, 9.5, 1.75)  # Game Selection to Final Dataset\n",
    "\n",
    "# Vertical arrows\n",
    "draw_arrow(7.5, 5, 7.5, 4.5)  # PGN Processing to Data Cleaning\n",
    "draw_arrow(7.5, 3, 7.5, 2.5)  # Data Cleaning to Game Selection\n",
    "\n",
    "# Add tight layout and save the figure with higher DPI\n",
    "plt.tight_layout(pad=1)  # Increased padding\n",
    "plt.savefig('/Users/samir/Desktop/Uppsala/Thesis/thesis_chess_code/src/data_processing/chess_data_pipeline.png', dpi=600, bbox_inches='tight')  # Increased DPI and specified full path\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chess",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
